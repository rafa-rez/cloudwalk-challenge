import random
import logging
from langchain_core.messages import RemoveMessage, AIMessage
from app.core.config import llm

logger = logging.getLogger(__name__)

def fallback_node(state):
    messages = state["messages"]
    options = [
        "Desculpe, sou especialista apenas em InfinitePay e finan√ßas.",
        "N√£o entendi. Poderia explicar melhor focando nos nossos servi√ßos?",
        "Isso foge do meu conhecimento atual."
    ]
    # Remove input ruim e n√£o salva output
    delete_op = RemoveMessage(id=messages[-1].id)
    return {
        "final_response": random.choice(options),
        "messages": [delete_op]
    }

def guardrail_node(state):
    messages = state["messages"]
    delete_op = RemoveMessage(id=messages[-1].id)
    return {
        "final_response": "üö´ A√ß√£o bloqueada por motivos de seguran√ßa e compliance.",
        "messages": [delete_op] 
    }

def human_handoff_node(state):
    # Mensagem base que ser√° refinada pela personalidade
    return {
        "final_response": "Entendido. Iniciando processo de transfer√™ncia para um atendente humano.",
        "messages": [AIMessage(content="[Sistema] Transferindo para atendimento humano...")]
    }

def personality_node(state):
    original_response = state.get("final_response", "")
    origin_agent = state.get("next_agent", "")
    
    if not original_response: return {"final_response": "Erro interno."}
    
    # --- CONFIGURA√á√ÉO DE FILTRO ---
    # Guardrail e Fallback: Mantemos est√°ticos (seguran√ßa/erro).
    # Human Handoff: AGORA PASSA (foi removido desta lista).
    ignored_agents = ["guardrail", "fallback"]
    
    if origin_agent in ignored_agents:
        return {"final_response": original_response}

    # Se a resposta for muito curta (ex: "Sim"), n√£o gasta token
    if len(original_response) < 5: 
        return {"final_response": original_response}

    system_prompt = (
        "Voc√™ √© o Editor de Texto da InfinitePay. Melhore a clareza e o tom.\n"
        "REGRAS ESTRITAS:\n"
        "1. Se houver 'Fonte: [url]' no texto original, VOC√ä DEVE MANTER no final.\n"
        "2. Se N√ÉO houver 'Fonte:' no original, JAMAIS INVENTE ou escreva 'Fonte:'.\n"
        "3. TOM: √ötil, direto e amig√°vel. Use emojis moderados (‚ö°, üöÄ, üë®‚Äçüíº).\n"
        f"TEXTO ORIGINAL:\n{original_response}"
    )
    
    try:
        response = llm.invoke(system_prompt)
        cleaned = response.content.strip().replace('"', '')
        
        # Valida√ß√£o extra para garantir que n√£o inventou fonte no handoff
        if "Fonte:" in cleaned and "http" not in cleaned:
            cleaned = cleaned.split("Fonte:")[0].strip()
            
        return {"final_response": cleaned}
        
    except Exception as e:
        logger.error(f"Erro no Personality: {e}")
        return {"final_response": original_response}