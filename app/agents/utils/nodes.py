import random
import logging
from langchain_core.messages import RemoveMessage, AIMessage
from app.core.config import llm

logger = logging.getLogger(__name__)

def fallback_node(state: dict) -> dict:
    """
    N√≥ de Fallback. Acionado quando a inten√ß√£o do usu√°rio n√£o √© compreendida.
    Remove a mensagem confusa do hist√≥rico para manter o contexto limpo.
    """
    messages = state["messages"]
    options = [
        "Desculpe, sou especialista apenas em InfinitePay e finan√ßas.",
        "N√£o entendi. Poderia reformular focando em nossos servi√ßos?",
        "Esse assunto foge do meu conhecimento t√©cnico atual."
    ]
    
    # Remove input do usu√°rio do hist√≥rico (Ef√™mero)
    delete_op = RemoveMessage(id=messages[-1].id)
    
    return {
        "final_response": random.choice(options),
        "messages": [delete_op]
    }

def guardrail_node(state: dict) -> dict:
    """
    N√≥ de Seguran√ßa (Guardrail).
    Bloqueia intera√ß√µes maliciosas e remove o prompt t√≥xico do hist√≥rico.
    """
    messages = state["messages"]
    delete_op = RemoveMessage(id=messages[-1].id)
    
    return {
        "final_response": "üö´ A√ß√£o bloqueada por motivos de seguran√ßa e compliance.",
        "messages": [delete_op] 
    }

def human_handoff_node(state: dict) -> dict:
    """
    N√≥ de Transbordo Humano.
    Inicia o protocolo de transfer√™ncia para atendimento n√≠vel 2.
    """
    return {
        "final_response": "Entendido. Iniciando processo de transfer√™ncia para um atendente humano.",
        "messages": [AIMessage(content="[Sistema] Transferindo para atendimento humano...")]
    }

def personality_node(state: dict) -> dict:
    """
    Agente de Personalidade (Editor).
    Refina a resposta final para adequa√ß√£o ao tom de voz da marca (Tone of Voice).
    
    Aplica filtros para n√£o processar mensagens de erro ou seguran√ßa.
    """
    original_response = state.get("final_response", "")
    origin_agent = state.get("next_agent", "")
    
    if not original_response: return {"final_response": "Erro interno de resposta."}
    
    # Agentes que N√ÉO devem ter resposta reescrita (Seguran√ßa/Erro)
    ignored_agents = ["guardrail", "fallback"]
    
    if origin_agent in ignored_agents:
        return {"final_response": original_response}

    # Evita gastar tokens com respostas muito curtas
    if len(original_response) < 5: 
        return {"final_response": original_response}

    system_prompt = (
        "Voc√™ √© o Editor de Texto da InfinitePay. Refine a resposta abaixo.\n"
        "REGRAS R√çGIDAS:\n"
        "1. Se houver 'Fonte: [url]' no texto original, VOC√ä DEVE MANTER no final.\n"
        "2. Se N√ÉO houver 'Fonte:' no original, JAMAIS INVENTE.\n"
        "3. TOM: Profissional, direto e amig√°vel. Use emojis com modera√ß√£o (‚ö°, üöÄ, üë®‚Äçüíº).\n"
        f"TEXTO ORIGINAL:\n{original_response}"
    )
    
    try:
        response = llm.invoke(system_prompt)
        cleaned = response.content.strip().replace('"', '')
        
        # Sanitiza√ß√£o Anti-Alucina√ß√£o de Fontes
        if "Fonte:" in cleaned and "http" not in cleaned:
            cleaned = cleaned.split("Fonte:")[0].strip()
            
        return {"final_response": cleaned}
        
    except Exception as e:
        logger.error(f"Erro no Agente de Personalidade: {e}")
        return {"final_response": original_response}